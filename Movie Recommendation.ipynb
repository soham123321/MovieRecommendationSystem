{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a30444-576f-49fb-bf02-bea8e77d1f79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df81b7a-b77d-4b7e-9ec7-9fd347dc662c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.9/site-packages (1.5.13)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.9/site-packages (from kaggle) (1.26.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from kaggle) (4.62.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.9/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from kaggle) (2.26.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->kaggle) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->kaggle) (3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7ecf3d-995f-4fa6-926d-37da0702fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/06/26 02:19:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session with Hive enabled\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"jupyter-spark\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\",\"/users/hive/warehouse\")\\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ea4fa5-eb1c-487a-b2d0-f0986e566c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import opendatasets as od\n",
    "# od.download(\"https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88ad468-94aa-4792-a1d4-76d6539470ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72628c5b-b97d-4d28-b7b7-501a70a07003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48caf316-79d8-4a9f-ba98-fd5c46c83373",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9260/2650065045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grouplens/movielens-20m-dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'movielens'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kaggle\n",
    "kaggle.api.dataset_download_files('grouplens/movielens-20m-dataset', path='movielens', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efec02b-2bb8-4b61-8f0a-725b3b2bcecc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2a50b6-b534-4ce8-b610-6a4199957db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col, explode, to_timestamp, concat_ws\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "movie = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/movie.csv\")\\\n",
    "        .select(\"movieId\", \"title\", split(col(\"genres\"), \"\\\\|\").alias(\"genres\"))\n",
    "\n",
    "rating = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/rating.csv\")\\\n",
    "         .withColumn(\"timestamp\",to_timestamp(\"timestamp\"))\n",
    "\n",
    "link = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/link.csv\")\n",
    "tag = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/tag.csv\")\n",
    "\n",
    "genome_tags = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/genome_tags.csv\")\n",
    "genome_score = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"./movielens/genome_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a04541-13c7-46ad-94e6-c5cadabbb000",
   "metadata": {},
   "source": [
    "## Creating the dataframe for algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be800f54-723c-4b61-8a57-3d5d65376213",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating = rating.groupBy(\"movieId\").agg(f.mean(\"rating\").alias(\"avg_rating\"), f.count(\"movieId\").alias(\"number_of_votes\"))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fcbc97-ea12-4ecb-9492-0432fc2df168",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = genome_score.join(genome_tags, genome_score[\"tagId\"] == genome_tags[\"tagId\"])\\\n",
    "                    .select(genome_score.movieId,genome_score.tagId,genome_score.relevance, genome_tags.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85722f8a-2988-4f48-934a-2dfd3ad9cee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# recommendation_df = movie.join(movie_rating, movie[\"movieId\"] == movie_rating[\"movieId\"])\\\n",
    "#                     .join(tag, movie[\"movieId\"] == tag[\"movieId\"])\\\n",
    "#                     .select(movie.movieId, movie.title,explode(movie.genres).alias(\"genres\"), movie_rating.avg_rating,\n",
    "#                             movie_rating.number_of_votes, tag.tag)\\\n",
    "#                     .groupBy(\"movieId\").agg(f.collect_list(\"tag\").alias(\"tags\"), \n",
    "#                                          f.collect_set(\"genres\").alias(\"genres\"))\\\n",
    "#                     .select(\"movieId\", concat_ws(\" \", \"tags\").alias(\"tags\"), concat_ws(\" \",\"genres\").alias(\"genres\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80c76b3-ceb5-45c5-b5d2-695f3187415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_df = movie.join(movie_rating, movie[\"movieId\"] == movie_rating[\"movieId\"])\\\n",
    "                    .join(tag, movie[\"movieId\"] == tag[\"movieId\"])\\\n",
    "                    .select(movie.movieId, movie.title,explode(movie.genres).alias(\"genres\"), movie_rating.avg_rating,\n",
    "                            movie_rating.number_of_votes, tag.tag)\\\n",
    "                    .groupBy(\"movieId\").agg(f.collect_set(\"tag\").alias(\"tags\"), \n",
    "                                         f.collect_set(\"genres\").alias(\"genres\"))\\\n",
    "                    .select(\"movieId\", concat_ws(\" \", \"tags\",\"genres\").alias(\"tags_genres\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99444264-cdde-406b-84b3-a43cb4660c21",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4132e6bb-f6bb-4286-858e-816a513012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, VectorAssembler, IDF, Normalizer\n",
    "\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "\n",
    "tags_genres_tokenizer = RegexTokenizer().setInputCol('tags_genres').setOutputCol('token_tags_genres')\n",
    "remove_stop_words = StopWordsRemover().setStopWords(stop_words)\\\n",
    "                        .setCaseSensitive(False).setInputCol(\"token_tags_genres\").setOutputCol(\"filtered_tags_genres\")\n",
    "\n",
    "count_vectorizer = CountVectorizer().setInputCol(\"filtered_tags_genres\").setOutputCol(\"tf_tags_genres\")\n",
    "\n",
    "idf = IDF().setInputCol('tf_tags_genres').setOutputCol('tfidf_tags_genres')\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"tfidf_tags_genres\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e7d928-b6c3-4614-a60f-275d86979134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, df_test = recommendation_df.randomSplit([0.7,0.3],0)\n",
    "fe_pipe = Pipeline(stages = [tags_genres_tokenizer,remove_stop_words, count_vectorizer, idf, normalizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33364f-8ad5-444f-b39e-52cb60c7773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "features = fe_pipe.fit(df_training).transform(df_training).select(\"features\").rdd.flatMap(lambda x: x).collect()\n",
    "# array = [row.features.toArray().tolist() for row in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0435a-1714-461b-a965-7bc45d06db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in features:\n",
    "    x.append(i.toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aefac-ad66-4544-9360-a509b670687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(map(list,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d0110-ae74-4280-8188-9a2d6c8f08d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
